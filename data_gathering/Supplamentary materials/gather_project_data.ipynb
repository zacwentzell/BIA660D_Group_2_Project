{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#select works to select from an item\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import selenium.webdriver.support.ui as ui\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To simulate the delay\n",
    "import random\n",
    "import time\n",
    "start_time = time.time()\n",
    "normal_delay = random.normalvariate(2, 0.5)\n",
    "time.sleep(normal_delay)    \n",
    "# print(\"--- %.5f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "def delay(t):\n",
    "    normal_delay = random.normalvariate(t, 0.5)\n",
    "    time.sleep(normal_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Chrome Driver\n",
    "driver = webdriver.Chrome(executable_path=r'/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go the main page of Amazon website\n",
    "driver.get('http://www.amazon.com')\n",
    "#We can get access the full page source with this line of code\n",
    "\"\"\"\n",
    "driver.page_source\n",
    "\"\"\"\n",
    "# Let's find the search field and click on it to make it ready to type on\n",
    "delay(4)\n",
    "search_field = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_field.click()\n",
    "delay(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we feed the keyword in search field\n",
    "search_field.send_keys('AKG headphones')\n",
    "search_field.send_keys(Keys.ENTER)\n",
    "delay(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_str(s, char):\n",
    "    index = 0\n",
    "    if char in s:\n",
    "        c = char[0]\n",
    "        for ch in s:\n",
    "            if ch == c:\n",
    "                if s[index:index+len(char)] == char:\n",
    "                    return index\n",
    "            index += 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find headphone feature on amazon page and narrow down searches into wireless headphones only\n",
    "wireless = driver.find_element_by_xpath('//*[@id=\"leftNavContainer\"]/ul[7]/div/li[4]/span/span/div/label/span/span')\n",
    "wireless.click()\n",
    "delay(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current page to html\n",
    "current_page = driver.page_source\n",
    "current_page_html = BS(current_page, 'html5lib')\n",
    "# find ul list containing products by id\n",
    "ul_list = current_page_html.find(\"ul\", {\"id\": \"s-results-list-atf\"})\n",
    "# initialize asin list to store all asin and product link to store all product links\n",
    "asin_list = []\n",
    "product_list = []\n",
    "for li in ul_list:\n",
    "    asin = li['data-asin']\n",
    "    asin_list.append(asin)\n",
    "    a_tag = li.find('a', href=True)['href']\n",
    "    product_list.append(a_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asin, prod in zip(asin_list, product_list):\n",
    "    driver.get(prod)\n",
    "    delay(3)\n",
    "    # spot [see all customer reviews]\n",
    "    try:\n",
    "        all_cust_reviews_link = driver.find_element_by_id('reviewSummary').find_element_by_id('dp-summary-see-all-reviews')\n",
    "        all_cust_reviews_link.click()\n",
    "        delay(3)\n",
    "        # get review page url\n",
    "        current_url = driver.current_url\n",
    "        index= find_str(current_url, '&reviewerType')\n",
    "        string = current_url[0:index] + \"&pageNumber=\" + current_url[index:]\n",
    "        # current page to HTML\n",
    "        all_cust_reviews_page = driver.page_source\n",
    "        all_cust_reviews_soup = BS(all_cust_reviews_page, 'html5lib')\n",
    "        # get total review counts\n",
    "        review_counts = all_cust_reviews_soup.find('span', attrs={'data-hook': 'total-review-count'}).get_text()\n",
    "        # remove , in counts\n",
    "        review_counts = int(review_counts.replace(',',''))\n",
    "        # # of pages\n",
    "        num_of_page = int(np.ceil(review_counts / 10))\n",
    "\n",
    "        add_eacpage_score_list = []\n",
    "        add_eacpage_date_list = []\n",
    "        add_eacpage_title_list = []\n",
    "        add_eacpage_review_list = []\n",
    "        add_eacpage_vote_list = []\n",
    "\n",
    "        for i in range(1,num_of_page+2):\n",
    "            # define page link\n",
    "            review_page_link = current_url[0:index] + \"&pageNumber=\" + str(i) + current_url[index:]\n",
    "            driver.get(review_page_link)\n",
    "            delay(2)\n",
    "            # current page to HTML\n",
    "            all_cust_reviews_page = driver.page_source\n",
    "            all_cust_reviews_soup = BS(all_cust_reviews_page, 'html5lib')\n",
    "            # get div containing all reviews body\n",
    "            reviews_soup_div = all_cust_reviews_soup.find('div', attrs={'id':'cm_cr-review_list'})\n",
    "            reviews_soup_div_data = reviews_soup_div.find_all('div', attrs={'class': 'a-section review'})\n",
    "            num_of_reviews = len(reviews_soup_div_data)\n",
    "            # for loop through reviews_soup_div_data\n",
    "            score_list = []\n",
    "            date_list = []\n",
    "            title_list = []\n",
    "            review_list = []\n",
    "            vote_list = []\n",
    "\n",
    "            for i in range(0, num_of_reviews):\n",
    "                review = reviews_soup_div_data[i].find('div', attrs={'class': 'a-section celwidget'})\n",
    "                # retrieve title score and append it to score_list\n",
    "                score = review.find('a', attrs={'class': 'a-link-normal'})['title'].encode(\"utf-8\")\n",
    "                score_list.append(score)\n",
    "                # retrieve date\n",
    "                date = review.find('span', attrs={'data-hook': 'review-date'}).get_text().encode(\"utf-8\")\n",
    "                date_list.append(date)\n",
    "                # retrieve title and append it to title_list\n",
    "                title = review.find('a', attrs={'data-hook': 'review-title'}).get_text().encode(\"utf-8\")\n",
    "                title_list.append(title)\n",
    "                # get review data and store in review_list\n",
    "                review_body = review.find('span', attrs={'data-hook': 'review-body'}).get_text().encode(\"utf-8\")\n",
    "                review_list.append(review_body)\n",
    "                # get [how many people found helpful]\n",
    "                vote = \"\"\n",
    "                if review.find('span', attrs={'data-hook': 'helpful-vote-statement'}):\n",
    "                    vote = review.find('span', attrs={'data-hook': 'helpful-vote-statement'}).get_text().encode(\"utf-8\")\n",
    "                vote_list.append(vote)\n",
    "            add_eacpage_score_list.extend(score_list)\n",
    "            add_eacpage_date_list.extend(date_list)\n",
    "            add_eacpage_title_list.extend(title_list)\n",
    "            add_eacpage_review_list.extend(review_list)\n",
    "            add_eacpage_vote_list.extend(vote_list)\n",
    "\n",
    "        df = pd.DataFrame({'Title':add_eacpage_title_list, 'Date': add_eacpage_date_list, 'Score': add_eacpage_score_list, 'Review Contents': add_eacpage_review_list, 'How Helpful': add_eacpage_vote_list})\n",
    "    #     df.to_csv(asin + '.csv')\n",
    "        df.to_csv(asin + \".csv\")\n",
    "    except NoSuchElementException:\n",
    "        driver.execute_script(\"window.history.go(-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
