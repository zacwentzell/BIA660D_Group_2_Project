{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#select works to select from an item\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import selenium.webdriver.support.ui as ui\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.14553 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#To simulate the delay\n",
    "import random\n",
    "import time\n",
    "start_time = time.time()\n",
    "normal_delay = random.normalvariate(2, 0.5)\n",
    "time.sleep(normal_delay)    \n",
    "print(\"--- %.5f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "def delay(t):\n",
    "    normal_delay = random.normalvariate(t, 0.5)\n",
    "    time.sleep(normal_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Chrome Driver\n",
    "#driver = webdriver.Chrome(executable_path=r'Dropbox/Academic/Courses/Term # 4/Web Analytics/chromedriver')\n",
    "driver = webdriver.Chrome(executable_path=r'Dropbox/Academic/Courses/Term # 4/Web Analytics/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndriver.page_source\\n'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's go the main page of Amazon website\n",
    "driver.get('http://www.amazon.com')\n",
    "#We can get access the full page source with this line of code\n",
    "\"\"\"\n",
    "driver.page_source\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's find the search field and click on it to make it ready to type on\n",
    "delay(4)\n",
    "search_field = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_field.click()\n",
    "search_field.send_keys('Headphones')\n",
    "delay(3)\n",
    "search_field.send_keys(Keys.ENTER)\n",
    "# READ MORE: http://selenium-python.readthedocs.io/locating-elements.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfirst_index = left_nav_container_words.index(\"Brand\")\\n\\nFeature_index = [i for i in range(len(left_nav_container_words)) if left_nav_container_words[i] == \"Feature\"]\\nfor index in Feature_index:\\n    if left_nav_container_words[index-1]==\"Headphone\":\\n        left_nav_container_words[index-1:index] = [\\' \\'.join(left_nav_container_words[index-1:index+1])]\\nlast_index = left_nav_container_words.index(\"Headphone Feature\")\\nBrands = left_nav_container_words[first_index+1:last_index]\\n'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the list of all brands\n",
    "\n",
    "left_nav_container = driver.find_elements_by_xpath(\".//span[contains(@class, 'a-label a-checkbox-label')]\") \n",
    "\n",
    "Brands = [y.text for y in left_nav_container]\n",
    "Brands = [\"RESET\"] + Brands\n",
    "Brands = [x for x in Brands if len(x)> 0]\n",
    "\"\"\"\n",
    "first_index = left_nav_container_words.index(\"Brand\")\n",
    "\n",
    "Feature_index = [i for i in range(len(left_nav_container_words)) if left_nav_container_words[i] == \"Feature\"]\n",
    "for index in Feature_index:\n",
    "    if left_nav_container_words[index-1]==\"Headphone\":\n",
    "        left_nav_container_words[index-1:index] = [' '.join(left_nav_container_words[index-1:index+1])]\n",
    "last_index = left_nav_container_words.index(\"Headphone Feature\")\n",
    "Brands = left_nav_container_words[first_index+1:last_index]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sony']\n"
     ]
    }
   ],
   "source": [
    "intended_checkboxes = ['sony']\n",
    "print(intended_checkboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ccc in intended_checkboxes:\n",
    "    string = \".//input[contains(@name, '{}')]\".format(ccc)\n",
    "    print(string)\n",
    "    driver.find_element_by_xpath(string ).click() # and @type='checkbox']\n",
    "    delay(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Review scraper function, we use this fu\n",
    "\n",
    "def scrape_reviews(item,product_name):\n",
    "    #item_name = item.text\n",
    "    #send_keys(Keys.COMMAND + Keys.RETURN) in order to open the links in the page\n",
    "    # Remember each item is a link to the page for each product\n",
    "    main_window = driver.current_window_handle\n",
    "    delay(5)\n",
    "    item.send_keys(Keys.COMMAND + Keys.RETURN) \n",
    "    \n",
    "    # Switch tab to the new tab, on the right\n",
    "    delay(4) \n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.TAB)    \n",
    "    # It is not enough. We need to put focus on the current visible tab\n",
    "    driver.switch_to_window(driver.window_handles[1])\n",
    "    # We need to get ASIN of the product: a unique code for each product on Amazon website\n",
    "    try:\n",
    "        Product_information_table = driver.find_element_by_id(\"productDetails_detailBullets_sections1\")\n",
    "    except:\n",
    "        Product_information_table = driver.find_element_by_id(\"detail-bullets\")\n",
    "    \n",
    "    Product_information = Product_information_table.text.split()\n",
    "    Cleaned_product_information = [re.sub(':','', x) for x in Product_information]\n",
    "    ASIN_index = Cleaned_product_information.index('ASIN')\n",
    "    product_ID = Cleaned_product_information[ASIN_index+1]\n",
    "    print(\"Product ID: {}\".format(product_ID))\n",
    "    # Now, we are interested to see all the reviews for the product, the following commands do this \n",
    "    delay(5)\n",
    "\n",
    "    # We have multiple pages of reviews each contain almost 10~20 reviews\n",
    "    # We need to sweep all of those pages\n",
    "    \n",
    "\n",
    "    all_reviews = {\"Name\":product_name, \"ID\": product_ID, \"reviews\": []} \n",
    "    #we have a few products without any reviews, let's skip them\n",
    "    try:\n",
    "        see_all = driver.find_element_by_css_selector(\".a-link-emphasis.a-text-bold\")\n",
    "        see_all.click()\n",
    "    except:\n",
    "        return product_ID, all_reviews\n",
    "         \n",
    "    q = 1\n",
    "    while ( True ):\n",
    "        q += 1\n",
    "        if q > 2:\n",
    "            break\n",
    "        # First, let's find the list of links to the classes containing the reviews' text\n",
    "        title_links = driver.find_elements_by_css_selector(\".a-size-base.a-link-normal.review-title.a-color-base.a-text-bold\")\n",
    "        date_links = driver.find_elements_by_css_selector(\".a-size-base.a-color-secondary.review-date\")\n",
    "        review_links = driver.find_elements_by_css_selector(\".a-size-base.review-text\")\n",
    "        rating_links = driver.find_elements_by_xpath(\".//a[contains(@title,  'out of 5 stars')]\")\n",
    "        comment_links = driver.find_elements_by_xpath(\"//*[contains(text(), 'Was this review helpful to you?')]\")\n",
    "        # And add them to the list of all the reviews\n",
    "        titles = [title_link.text for title_link in title_links]\n",
    "        dates = [date_link.text for date_link in date_links]\n",
    "        ratings = [rating_link.get_attribute(\"title\") for rating_link in rating_links]\n",
    "        reviews = [review_link.text for review_link in review_links]\n",
    "        comments = [comment_link.text for comment_link in comment_links]\n",
    "        compact_reviews = zip(titles, dates, ratings, reviews, comments)\n",
    "        all_reviews[\"reviews\"] += compact_reviews\n",
    "        # although we can click on the link to the other pages. \n",
    "        \"\"\"\n",
    "        other_pages = driver.find_elements_by_class_name(\"page-button\")\n",
    "        print([t.text for t in other_pages])\n",
    "        \"\"\"\n",
    "\n",
    "        #print the selected button\n",
    "        current_page = driver.find_element_by_css_selector(\".a-selected.page-button\")\n",
    "        print(\"The reviews on page {} successfully extraced\".format(current_page.text))\n",
    "\n",
    "        # we prefer to use the Nextâ†’ button\n",
    "        try:\n",
    "            next_page = driver.find_element_by_class_name(\"a-last\")\n",
    "        except:\n",
    "            next_page = None\n",
    "            \n",
    "        \n",
    "        #We can also use the link text to find the intended links\n",
    "        \n",
    "        \"\"\"\n",
    "        print(driver.find_element_by_link_text('2').text)\n",
    "        \"\"\"\n",
    "        # We continue the sweeping the review pages until getting to the last page\n",
    "        \n",
    "        try:\n",
    "            is_last_page = driver.find_element_by_css_selector(\".a-disabled.a-last\")\n",
    "        except:\n",
    "            is_last_page = None\n",
    "            \n",
    "        if (is_last_page != None):\n",
    "            print(\"All the reviews extracted successfully\")\n",
    "            print(\"-------------------------------------------------\")\n",
    "            break\n",
    "        delay(10)\n",
    "        next_page.click()\n",
    "        delay(5)\n",
    "    # We extracted all the reviews from this page. Let's close the current tab    \n",
    "    delay(4)    \n",
    "    driver.close()\n",
    "    # And remember to put driver focus on current window which will be the window opener\n",
    "    driver.switch_to_window(main_window)\n",
    "    #driver.close()\n",
    "    return product_ID, all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(whatever):\n",
    "    for i in whatever:\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: Sony High-Fidelity In-ear Headphones / Earphones Lightweight Perfect for Sports (Certified Refurbished) (MD-X15, White)\n",
      "Product Name: SENSO Bluetooth Headphones, Best Wireless Sports Earphones w/ Mic IPX7 Waterproof HD Stereo Sweatproof Earbuds for Gym Running Workout 8 Hour Battery Noise Cancelling Headsets\n",
      "Product Name: AmazonBasics Lightweight On-Ear Headphones - Black\n",
      "Product Name: Apple MD827LL/A EarPods with Remote and Mic - Standard Packaging - White\n",
      "Product Name: Mpow 059 Bluetooth Headphones Over Ear, Hi-Fi Stereo Wireless Headset, Foldable, Soft Memory-Protein Earmuffs, w/ Built-in Mic and Wired Mode for PC/ Cell Phones/ TV\n",
      "Product Name: Panasonic RP-HJE120-PPK In-Ear Stereo Earphones, Black\n",
      "Product Name: AILIHEN C8 Headphones with Microphone and Volume Control Folding Lightweight Headset for Cellphones Tablets Smartphones Laptop Computer PC Mp3/4 (Grey/Mint)\n",
      "Product Name: Mpow 059 Bluetooth Headphones Over Ear, Hi-Fi Stereo Wireless Headset, Foldable, Soft Memory-Protein Earmuffs, w/ Built-in Mic and Wired Mode for PC/ Cell Phones/ TV\n",
      "Product Name: On Ear Headphones with Mic, Vogek Wired Foldable Bass Headphones with Volume Control and Microphone-Black\n",
      "Product Name: OUCOMI Wired Headphones Stereo Earphones In-Ear Earbuds Control Crystal Sound with Mic White\n",
      "Product Name: COWIN E8 Active Noise Cancelling Headphone Bluetooth Headphones with Microphone Hi-Fi Deep Bass Wireless Headphones Over Ear Stereo Sound 20 Hour Playtime for Travel Work TV Computer Phone - Black\n",
      "Product Name: Mpow Flame Bluetooth Headphones Waterproof IPX7, Wireless Earbuds Sport, Richer Bass HiFi Stereo In-Ear Earphones w/ Mic, Case, 7-9 Hrs Playback Noise Cancelling Headsets (Comfy & Fast Pairing)\n",
      "Product ID: B0753GRNQZ\n",
      "The reviews on page 1 successfully extraced\n",
      "Product Name: Earbuds, HokoAcc In-Ear Headphones Noise Isolation Headsets Heavy Bass Earphones with Microphone for iPhone Samsung iPad and Most Android Phones (Gold)\n",
      "Product ID: B079D5T48Z\n",
      "The reviews on page 1 successfully extraced\n",
      "Product Name: Ailihen I35 Stereo Lightweight Foldable Headphones Adjustable Headband Headsets with Microphone 3.5mm for Cellphones Smartphones Iphone Laptop Computer Mp3/4 Earphones (Grey/Green)\n",
      "Product ID: B015WBVJGA\n",
      "The reviews on page 1 successfully extraced\n",
      "Product Name: Bluetooth Headphones, Otium Best Wireless Sports Earphones w/ Mic IPX7 Waterproof HD Stereo Sweatproof In Ear Earbuds for Gym Running Workout 8 Hour Battery Noise Cancelling Headsets\n",
      "Product ID: B018APC4LE\n",
      "The reviews on page 1 successfully extraced\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-a17fbaf62d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Product Name: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproduct_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscraped_products\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mproduct_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#df = pd.DataFrame.from_dict(all_reviews, orient='columns', dtype=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#df.to_csv('{}.csv'.format(list(all_items_reviews.keys())[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-256-c793fb7d1a4e>\u001b[0m in \u001b[0;36mscrape_reviews\u001b[0;34m(item, product_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mdelay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mnext_page\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mdelay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-248-58f334cc1a80>\u001b[0m in \u001b[0;36mdelay\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnormal_delay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalvariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_delay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Now we selected the intended list of products and want to sweep the list of shown product\n",
    "\"\"\"now we are ready to get reviews, but first we should click on the items one-by-one\"\"\"\n",
    "main_window = driver.current_window_handle\n",
    "driver.switch_to_window(main_window)\n",
    "\n",
    "items_names = []\n",
    "\n",
    "try:\n",
    "    with open('successfully_scraped_products.pickle', 'rb') as handle:\n",
    "        scraped_products = pickle.load(handle)\n",
    "except:\n",
    "    scraped_products = []\n",
    "    with open('successfully_scraped_products.pickle', 'wb') as handle:\n",
    "        pickle.dump([], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    search_items_links = driver.find_elements_by_css_selector(\".a-link-normal.s-access-detail-page.s-color-twister-title-link.a-text-normal\")\n",
    "    \n",
    "    items_names += [ link.text for link in search_items_links]\n",
    "\n",
    "    item_generator = gen(items_names)\n",
    "    \n",
    "    for item in search_items_links:\n",
    "        product_name = next(item_generator)\n",
    "        print(\"Product Name: {}\".format(product_name))\n",
    "        if product_name not in scraped_products:\n",
    "            product_ID, all_reviews = scrape_reviews(item, product_name)        \n",
    "            #df = pd.DataFrame.from_dict(all_reviews, orient='columns', dtype=None)\n",
    "            #df.to_csv('{}.csv'.format(list(all_items_reviews.keys())[0]))\n",
    "            #df.to_csv('{}.csv'.format(product_ID))\n",
    "            with open('{}.pickle'.format(product_ID), 'wb') as fp:\n",
    "                pickle.dump(all_reviews, fp)\n",
    "            scraped_products += [product_name]\n",
    "            with open('successfully_scraped_products.pickle', 'wb') as handle:\n",
    "                pickle.dump(scraped_products, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    try:\n",
    "        next_page = driver.find_element_by_class_name(\"pagnRA\")\n",
    "    except:\n",
    "        next_page = None\n",
    "\n",
    "        \n",
    "    try:\n",
    "        is_last_page = driver.find_element_by_css_selector(\"pagnRA1\")\n",
    "    except:\n",
    "        is_last_page = None\n",
    "\n",
    "    if (is_last_page != None or next_page == None):\n",
    "        print(\"All the products' reviews extracted successfully\")\n",
    "        print(\"-------------------------------------------------\")\n",
    "        break\n",
    "    next_page.click()\n",
    "    delay(5)\n",
    "\n",
    "# an important point to manage class names containing space\n",
    "# we need to substitute spaces with periods\n",
    "# Here we get all the items showed in the first respose page\n",
    "# At the moment we just sweep the items at the first page\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can also use the represented text to find intended classes\n",
    "\"\"\"\n",
    "X = driver.find_elements_by_xpath(\"//*[contains(text(), '5.0 out of 5 stars')]\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
